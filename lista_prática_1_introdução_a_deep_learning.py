# -*- coding: utf-8 -*-
"""Lista Prática 1 - Introdução a Deep Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eBxaZ4mUayDOg8VMAf0M1CxJ3Mt6SwOc

# Lista Prática 1 - Modelos de Classificação para Fashion MNIST

#### Rafael da Silva Barros (rsb7)
#### Gabriel Walisson Alexandre Matias (gwam)

# Imports e Downloads
"""

import tensorflow as tf
from tensorflow.keras import layers, models, datasets, callbacks
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input

from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from scipy.stats import randint
import time
from tabulate import tabulate, tabulate_formats
import torch
import random

from sklearn.model_selection import train_test_split
from sklearn import svm, ensemble, linear_model, neighbors
from sklearn import gaussian_process, naive_bayes, tree
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Verificando se a GPU está ativa
print('GPUs available:',len(tf.config.list_physical_devices('GPU')))

"""# API Local"""

# Mapeamento das classes
label_dict = {
    0: 'T-shirt/Top',
    1: 'Trouser',
    2: 'Pullover',
    3: 'Dress',
    4: 'Coat',
    5: 'Sandal',
    6: 'Shirt',
    7: 'Sneaker',
    8: 'Bag',
    9: 'Ankle boot'
}

# Semente aleatória do sklearn
RD_SEED = 42

# Predefinindo arrays de resultado
model_list = []
exec_times = []
accuracies = []
worst_classes = []
worst_labels = []
worst_results = []


# Função para printar imagens
def imshow(image):
    img = image*255.0
    imgplot = plt.imshow(img, 'gray')
    plt.show()


# Função de treino dos modelos de machine learning
def train_ml_model(model, name, train_X, train_y):

  # Contagem do tempo de execução do treino
  start_time = time.time()
  model.fit(train_X, train_y)
  end_time = time.time()

  # Calculando tempo de execução
  exec_time = end_time - start_time
  print(f'Tempo de execução do {name} em segundos: {np.round(exec_time,2)}')

  # Salvando os dados do modelo
  model_list.append(name)
  exec_times.append(np.round(exec_time,2))


# Função de avaliação dos modelos de machine learning
def evaluate_ml_model(model, name, test_X, test_y, labels):

  # Fazendo a classificação do conjunto de testes
  pred_y = model.predict(test_X)

  # Medindo a acurácia do modelo
  accuracy = accuracy_score(test_y, pred_y)
  print(f"\n{name} accuracy:",np.round(accuracy,4))

  # Exibindo o relatório de classificação
  print(f"\nClassification Report do {name}")
  print(classification_report(test_y, pred_y))

  # Definindo a matriz de confusão
  cm = confusion_matrix(test_y, pred_y)

  # Calculando a TPR
  TPR = cm.diagonal()/cm.sum(axis=1)
  print(f'\nTPR por classe do {name}:',np.round(TPR,4))

  # Exibindo a matriz de confusão
  print('\nConfusion Matrix')
  ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels).plot();

  # Salvando os dados do modelo
  accuracies.append(np.round(accuracy,4))
  worst_classes.append(np.round(TPR.argmin(),4))
  worst_results.append(np.round(TPR.min(),4))


# Função de treino dos modelos de deep learning
def train_dl_model(model, name, train_X, train_y):

  # Treinamento do modelo
  start_time = time.time()
  history = model.fit(train_X, train_y, epochs=10, batch_size=128, validation_split=1/6)
  end_time = time.time()

  # Calcular tempo de execução
  exec_time = end_time - start_time
  print(f'\nTempo de execução do {name} em segundos: {np.round(exec_time,2)}')

  # Plotar gráfico de acurácia durante o treino
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  ax = plt.gca()
  ax.set_ylim([0,1])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['Train', 'Validation'])
  plt.show()

  # Plotar gráfico de custo durante o treino
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  ax = plt.gca()
  ax.set_ylim([0,1])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['Train', 'Validation'])
  plt.show()

  # Salvando os dados do modelo
  model_list.append(name)
  exec_times.append(np.round(exec_time,2))


# Função de avaliação de modelos deep learning
def evaluate_dl_model(model, name, test_X, test_y, labels):

  # Avaliação do modelo no conjunto de teste
  test_loss, test_acc = model.evaluate(test_X, test_y)
  print(f'{name} Test Accuracy: {np.round(test_acc,4)}, {name} Test Loss: {np.round(test_loss,4)}\n')

  # Isolando os resultados para comparação
  test_y = np.argmax(test_y, axis=1)

  # Fazendo a classificação do conjunto de testes
  pred_y = np.argmax(model.predict(test_X), axis=1)

  # Medindo a acurácia do modelo
  accuracy = accuracy_score(test_y, pred_y)

  # Relatório de classificação do modelo
  print(f"\nClassification Report do {name}")
  print(classification_report(test_y, pred_y))

  # Definindo a matriz de confusão
  cm = confusion_matrix(test_y, pred_y)

  # Calculando a TPR
  TPR = cm.diagonal()/cm.sum(axis=1)
  print(f'\nTPR por classe do {name}:',np.round(TPR,4))

  # Exibindo a matriz de confusão
  print('\nConfusion Matrix')
  ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels).plot();

  # Adicionando os dados do modelo aos vetores de resultado
  accuracies.append(np.round(accuracy,4))
  worst_classes.append(np.round(TPR.argmin(),4))
  worst_results.append(np.round(TPR.min(),4))


# Função de treino dos modelos de transfer learning
def train_tl_model(model, name, train_dataset):

  # Treinamento do modelo
  start_time = time.time()
  history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)
  end_time = time.time()

  # Calcular tempo de execução
  exec_time = end_time - start_time
  print(f'\nTempo de execução do {name} em segundos: {np.round(exec_time,2)}')

  # Plotar gráfico de acurácia durante o treino
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  ax = plt.gca()
  ax.set_ylim([0,1])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['Train', 'Validation'])
  plt.show()

  # Plotar gráfico de custo durante o treino
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  ax = plt.gca()
  ax.set_ylim([0,1])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['Train', 'Validation'])
  plt.show()

  # Salvando os dados do modelo
  model_list.append(name)
  exec_times.append(np.round(exec_time,2))


# Função de avaliação de modelos transfer learning
def evaluate_tl_model(model, name, test_dataset, labels):

  # Avaliação do modelo no conjunto de teste
  test_loss, test_acc = model.evaluate(test_dataset)
  print(f'{name} Test Accuracy: {np.round(test_acc,4)}, {name} Test Loss: {np.round(test_loss,4)}\n')

  # Isolando os resultados para comparação
  test_y = np.concatenate([y for x, y in test_dataset], axis=0)
  test_y = np.argmax(test_y, axis=1)

  # Fazendo a classificação do conjunto de testes
  pred_y = np.argmax(model.predict(test_dataset), axis=1)

  # Medindo a acurácia do modelo
  accuracy = accuracy_score(test_y, pred_y)

  # Relatório de classificação do modelo
  print(f"\nClassification Report do {name}")
  print(classification_report(test_y, pred_y))

  # Definindo a matriz de confusão
  cm = confusion_matrix(test_y, pred_y)

  # Calculando a TPR
  TPR = cm.diagonal()/cm.sum(axis=1)
  print(f'\nTPR por classe do {name}:',np.round(TPR,4))

  # Exibindo a matriz de confusão
  print('\nConfusion Matrix')
  ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels).plot();

  # Adicionando os dados do modelo aos vetores de resultado
  accuracies.append(np.round(accuracy,4))
  worst_classes.append(np.round(TPR.argmin(),4))
  worst_results.append(np.round(TPR.min(),4))

"""# Tratamento dos Dados"""

# Fazendo download do dataset
(train_X, train_y), (test_X, test_y) = datasets.fashion_mnist.load_data()

# Normalizando os dados
train_X = train_X.astype('float32') / 255.0
test_X = test_X.astype('float32') / 255.0

print('Train set size:',len(train_X),'; shape:',train_X.shape)
print('Test set size:',len(test_X),'; shape:',test_X.shape)

# for i in range(len(train_X)):
#   if label_dict[train_y[i]] == 'Shirt':
#     imshow(train_X[i])

# Contabilizando ocorrências das clases nos dados de treino
classes, counts = np.unique(train_y, return_counts=True)

# Traduzindo as classes para as labels
labels = []
for i in range(len(classes)):
  labels.append(label_dict[classes[i]])

# Setando os gráficos de distribuição
plt.figure(figsize=(9, 3))
plt.title('Distribuição dos dados de treino por classe')
plt.xlabel('Classes')
plt.ylabel('Ocorrências')
sns.barplot(x=labels, y=counts, width=0.5, hue=labels)
for i in range(len(counts)):
  plt.text(labels[i], counts[i], str(counts[i]), ha='center', va='bottom')

plt.figure()
plt.pie(counts, labels=labels, autopct='%0.1f%%')

plt.show()

# Contabilizando ocorrências das clases nos dados de teste
classes, counts = np.unique(test_y, return_counts=True)

# Traduzindo as classes para as labels
labels = []
for i in range(len(classes)):
  labels.append(label_dict[classes[i]])

# Setando os gráficos de distribuição
plt.figure(figsize=(9, 3))
plt.title('Distribuição dos dados de teste por classe')
plt.xlabel('Classes')
plt.ylabel('Ocorrências')
sns.barplot(x=labels, y=counts, width=0.5, hue=labels)
for i in range(len(counts)):
  plt.text(labels[i], counts[i], str(counts[i]), ha='center', va='bottom')

plt.figure()
plt.pie(counts, labels=labels, autopct='%0.1f%%')

plt.show()

"""# Modelo base"""

# Linearizando dados
lin_train_X = train_X.reshape(len(train_X), -1)
lin_test_X = test_X.reshape(len(test_X), -1)

# Verificando o formato dos dados
print('Train set size:',len(lin_train_X),'; shape:',lin_train_X.shape)
print('Test set size:',len(lin_test_X),'; shape:',lin_test_X.shape)

name = 'Random Forest'

# Criando o classificador
rf_model = ensemble.RandomForestClassifier(n_estimators=150, random_state=RD_SEED)

# Treinando e avaliando o classificador
train_ml_model(rf_model, name, lin_train_X, train_y)
evaluate_ml_model(rf_model, name, lin_test_X, test_y, labels)

name = 'SVM'

# Criando o classificador
svm_model = svm.SVC(kernel='linear')

# Treinando e avaliando o classificador
train_ml_model(svm_model, name, lin_train_X, train_y)
evaluate_ml_model(svm_model, name, lin_test_X, test_y, labels)

name = 'SGD'

# Criando o classificador
sgd_model = linear_model.SGDClassifier(loss='log_loss', random_state=RD_SEED)

# Treinando e avaliando o classificador
train_ml_model(sgd_model, name, lin_train_X, train_y)
evaluate_ml_model(sgd_model, name, lin_test_X, test_y, labels)

name = 'KNN'

# Criando o classificador
knn_model = neighbors.KNeighborsClassifier(n_neighbors=5)

# Treinando e avaliando o classificador
train_ml_model(knn_model, name, lin_train_X, train_y)
evaluate_ml_model(knn_model, name, lin_test_X, test_y, labels)

name = 'Naive Bayes'

# Criando o classificador
gnb_model = naive_bayes.GaussianNB()

# Treinando e avaliando o classificador
train_ml_model(gnb_model, name, lin_train_X, train_y)
evaluate_ml_model(gnb_model, name, lin_test_X, test_y, labels)

name = 'Decision Tree'

# Criando o classificador
dt_model = tree.DecisionTreeClassifier(criterion='log_loss', max_depth=500)

# Treinando e avaliando o classificador
train_ml_model(dt_model, name, lin_train_X, train_y)
evaluate_ml_model(dt_model, name, lin_test_X, test_y, labels)

"""# MLP"""

# Carregamento e pré-processamento dos dados
(train_X, train_y), (test_X, test_y) = datasets.fashion_mnist.load_data()

# Redimensionamento e normalização dos dados
train_X = train_X.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_X = test_X.reshape((10000, 28, 28, 1)).astype('float32') / 255

# Conversão de rótulos em categorias
train_y = tf.keras.utils.to_categorical(train_y, 10)
test_y = tf.keras.utils.to_categorical(test_y, 10)

print('Train set size:',len(train_X),'; shape:',train_X.shape)
print('Test set size:',len(test_X),'; shape:',test_X.shape)

name = 'MLP'

# Criação do modelo MLP
mlp = models.Sequential([
    layers.Flatten(input_shape=(28, 28, 1)),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compilação do modelo com um otimizador que tem uma taxa de aprendizado ajustada
opt = tf.keras.optimizers.Adam(learning_rate=0.001)
mlp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

# Callback para parar o treinamento quando não houver melhora
early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)

# Treinamento do modelo
train_dl_model(mlp, name, train_X, train_y)
evaluate_dl_model(mlp, name, test_X, test_y, labels)

"""
# Rede Convolucional"""

# Carregamento e pré-processamento dos dados
(train_X, train_y), (test_X, test_y) = tf.keras.datasets.fashion_mnist.load_data()

train_X = train_X.reshape(train_X.shape[0], 28, 28, 1) / 255.0
test_X = test_X.reshape(test_X.shape[0], 28, 28, 1) / 255.0

train_y = tf.keras.utils.to_categorical(train_y, 10)
test_y = tf.keras.utils.to_categorical(test_y, 10)

print('Train set size:',len(train_X),'; shape:',train_X.shape)
print('Test set size:',len(test_X),'; shape:',test_X.shape)

name = 'LeNet'

# Construção do modelo de CNN
lenet = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compilação do modelo
lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callback para salvar o melhor modelo durante o treinamento
checkpoint = callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)

# Treinando e avaliando o modelo
train_dl_model(lenet, name, train_X, train_y)
evaluate_dl_model(lenet, name, test_X, test_y, labels)

"""# Rede Convolucional consolidada"""

# Carregando o dataset Fashion MNIST
(train_X, train_y), (test_X, test_y) = datasets.fashion_mnist.load_data()

# Limitando o número de amostras para não estourar a RAM
MAX_SAMPLES = 1500
train_idx = random.sample(range(len(train_X)), MAX_SAMPLES)
test_idx = random.sample(range(len(test_X)), MAX_SAMPLES)

# Amostrando os conjuntos de dados
train_X = train_X[train_idx]
train_y = train_y[train_idx]
test_X = test_X[test_idx]
test_y = test_y[test_idx]

# Adicionando uma dimensão de canal
train_X = np.expand_dims(train_X, -1).astype('float32')
test_X = np.expand_dims(test_X, -1).astype('float32')

# Convertendo imagens de grayscale para RGB
train_X = np.repeat(train_X, 3, axis=-1)
test_X = np.repeat(test_X, 3, axis=-1)

print('Train set size:',len(train_X),'; shape:',train_X.shape)
print('Test set size:',len(test_X),'; shape:',test_X.shape)

# Categorizando as classes
train_y = tf.one_hot(train_y, 10)
test_y = tf.one_hot(test_y, 10)

# Formatando os dados para o formato de entrada das redes
train_X = np.array([tf.image.resize(img, (224,224)) for img in train_X])
test_X = np.array([tf.image.resize(img, (224,224)) for img in test_X])

print('Train set size:',len(train_X),'; shape:',train_X.shape)
print('Test set size:',len(test_X),'; shape:',test_X.shape)

name = 'TL ResNet50'

# Configurando o modelo
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Congelar a base do modelo

# Construção do novo modelo para o novo conjunto de classes
modelResNet50 = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

# Compilar o modelo com as configurações de otimização e perda
modelResNet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Treinar e avaliar o modelo
train_dl_model(modelResNet50, name, train_X, train_y)
evaluate_dl_model(modelResNet50, name, test_X, test_y, labels)

"""# Comparação"""

# Comparando acurácias
plt.figure()
plt.title('Acurácia por modelo')
plt.xlabel('Modelos')
plt.ylabel('Acurácias')
sns.barplot(x=model_list,y=accuracies,width=0.5, hue=model_list)
for i in range(len(model_list)):
  plt.text(model_list[i],accuracies[i],str(np.round(accuracies[i],4)),ha='center',va='bottom')
plt.show()

#Comparando tempos de execução
plt.figure()
plt.title('Tempo de execução por modelo')
plt.xlabel('Modelos')
plt.ylabel('Tempos de execução (s)')
sns.barplot(x=model_list,y=exec_times,width=0.5, hue=model_list)
for i in range(len(model_list)):
  plt.text(model_list[i],exec_times[i],str(np.round(exec_times[i], 2)),ha='center',va='bottom')
plt.show()

# Organizando os dados
for i in range(len(worst_classes)):
  worst_labels.append(label_dict[worst_classes[i]])

data = {
    'models': model_list,
    'piores_classes': worst_labels,
    'piores_resultados': np.round(worst_results, 3)
}

# Comparando piores classes e resultados
print('Piores resultados por modelo')
print(tabulate(data, headers='keys', tablefmt='outline'))